import json
import re
import logging
from typing import Dict, Any, List, Tuple
from collections import Counter
import numpy as np

logger = logging.getLogger(__name__)

class AdvancedSentimentAnalyzer:
    """An√°lise de sentimento avan√ßada com dicion√°rio expandido, n-gramas e detec√ß√£o de contexto"""
    
    def __init__(self):
        self._initialize_dictionaries()
        self._initialize_patterns()
        self._initialize_emoji_mapping()
        
    def _initialize_dictionaries(self):
        """Inicializa dicion√°rios expandidos com 500+ palavras"""
        
        # PALAVRAS MUITO POSITIVAS - Peso 4.0
        self.very_positive = [
            # Amor e afeto intenso
            'amo', 'adoro', 'love', 'paix√£o', 'adora√ß√£o', 'venera√ß√£o', 'idolatro',
            
            # Excel√™ncia e perfei√ß√£o
            'excelente', 'excellent', 'perfeito', 'perfect', 'impec√°vel', 'primoroso',
            'extraordin√°rio', 'excepcional', 'magn√≠fico', 'espl√™ndido', 'sublime',
            'fant√°stico', 'fantastic', 'sensacional', 'espetacular', 'deslumbrante',
            'maravilhoso', 'wonderful', 'incr√≠vel', 'incredible', 'fenomenal',
            
            # Emo√ß√µes positivas intensas
            'euforia', '√™xtase', 'alegria extrema', 'felicidade plena', 'radiante',
            'exultante', 'jubiloso', 'extasiado', 'arrebatado', 'encantado',
            'deslumbrado', 'fascinado', 'embevecido', 'entusiasmado',
            
            # Gratid√£o e reconhecimento
            'gratid√£o imensa', 'profundamente grato', 'reconhecimento eterno',
            'agradecimento sincero', 'imensamente grato'
        ]
        
        # PALAVRAS POSITIVAS - Peso 2.5
        self.positive_words = [
            # Qualidade e aprova√ß√£o
            '√≥timo', 'great', 'bom', 'good', 'excelente', 'muito bom', 'bacana',
            'legal', 'show', 'top', 'massa', 'demais', 'irado', 'maneiro',
            'aprovado', 'recomendado', 'aproveit√°vel', 'v√°lido', '√∫til',
            
            # Emo√ß√µes positivas
            'feliz', 'happy', 'alegre', 'contente', 'satisfeito', 'realizado',
            'orgulhoso', 'confiante', 'otimista', 'esperan√ßoso', 'animado',
            'entusiasmado', 'motivado', 'inspirado', 'energizado',
            
            # Sucesso e conquista
            'sucesso', 'vit√≥ria', 'conquista', 'triunfo', '√™xito', 'realiza√ß√£o',
            'progresso', 'avan√ßo', 'melhoria', 'evolu√ß√£o', 'crescimento',
            
            # Relacionamentos
            'carinho', 'ternura', 'afeto', 'proximidade', 'intimidade',
            'companheirismo', 'cumplicidade', 'harmonia', 'paz', 'tranquilidade'
        ]
        
        # PALAVRAS LEVEMENTE POSITIVAS - Peso 1.0
        self.light_positive = [
            'ok', 'okay', 'bem', 'razo√°vel', 'aceit√°vel', 'decent', 'regular',
            'normal', 'comum', 'padr√£o', 'esperado', 'previsto', 'adequado',
            'suficiente', 'satisfat√≥rio', 'funcional', 'operacional',
            'interessante', 'curioso', 'intrigante', 'chamativo', 'atrativo'
        ]
        
        # PALAVRAS MUITO NEGATIVAS - Peso -4.0
        self.very_negative = [
            # √ìdio e avers√£o intensa
            'odeio', 'detesto', 'abomino', 'repudio', 'desprezo', 'hate',
            'execra√ß√£o', 'avers√£o total', 'nojo absoluto', 'repugn√¢ncia',
            
            # Qualidade terr√≠vel
            'terr√≠vel', 'terrible', 'horr√≠vel', 'horrible', 'p√©ssimo', 'awful',
            'horroroso', 'assombroso', 'aterrorizante', 'abomin√°vel', 'repulsivo',
            'nauseante', 'repugnante', 'desprez√≠vel', 'ign√≥bil', 'vil',
            
            # Emo√ß√µes negativas extremas
            '√≥dio', 'f√∫ria', 'c√≥lera', 'ira', 'raiva extrema', 'revolta',
            'indigna√ß√£o', 'desespero', 'desalento', 'devasta√ß√£o', 'aniquila√ß√£o',
            'pavor', 'terror', 'p√¢nico', 'horror', 'pavoroso',
            
            # Falha total
            'fracasso total', 'ru√≠na completa', 'desastre', 'cat√°strofe',
            'trag√©dia', 'calamidade', 'infort√∫nio'
        ]
        
        # PALAVRAS NEGATIVAS - Peso -2.5
        self.negative_words = [
            # Qualidade ruim
            'ruim', 'bad', 'p√©ssimo', 'pobre', 'fraco', 'inferior', 'defeituoso',
            'falho', 'problem√°tico', 'inadequado', 'insuficiente', 'limitado',
            
            # Emo√ß√µes negativas
            'triste', 'sad', 'melanc√≥lico', 'deprimido', 'abatido', 'desanimado',
            'desiludido', 'decepcionado', 'frustrado', 'irritado', 'aborrecido',
            'chateado', 'incomodado', 'perturbado', 'angustiado', 'aflito',
            
            # Medo e ansiedade
            'medo', 'receio', 'temor', 'apreens√£o', 'ansiedade', 'nervosismo',
            'inquieta√ß√£o', 'desassossego', 'intranquilidade', 'agonia',
            
            # Problemas e dificuldades
            'problema', 'dificuldade', 'obst√°culo', 'impedimento', 'complica√ß√£o',
            'transtorno', 'dist√∫rbio', 'confus√£o', 'bagun√ßa', 'caos'
        ]
        
        # PALAVRAS LEVEMENTE NEGATIVAS - Peso -1.0
        self.light_negative = [
            'estranho', 'weird', 'esquisito', 'diferente', 'incomum', 'at√≠pico',
            'confuso', 'confusing', 'complicado', 'complexo', 'dif√≠cil', 'hard',
            'cansativo', 'tedioso', 'mon√≥tono', 'repetitivo', 'chato', 'boring',
            'lento', 'demorado', 'vagaroso', 'lerdo'
        ]
        
        # INTENSIFICADORES - Multiplicam por 1.6
        self.intensifiers = [
            'muito', 'super', 'extremely', 'really', 'totally', 'absolutely',
            'completamente', 'totalmente', 'inteiramente', 'plenamente',
            'demais', 'bastante', 'bem', 'mega', 'ultra', 'hiper',
            'extremamente', 'profundamente', 'intensamente', 'fortemente',
            'incrivelmente', 'imensamente', 'enormemente', 'extraordinariamente',
            'excepcionalmente', 'surpreendentemente', 'impressionantemente'
        ]
        
        # DIMINUIIDORES - Multiplicam por 0.6
        self.diminishers = [
            'pouco', 'little', 'somewhat', 'ligeiramente', 'levemente',
            'sutilmente', 'moderadamente', 'relativamente', 'razoavelmente',
            'meio', 'half', 'quase', 'almost', 'praticamente'
        ]
        
        # NEGADORES - Invertem o sentimento
        self.negators = [
            'n√£o', 'not', 'nunca', 'never', 'jamais', 'nenhum', 'nenhuma',
            'sem', 'without', 'imposs√≠vel', 'impossible', 'nem', 'neither',
            'tampouco', 'sequer', 'absolutamente n√£o', 'de jeito nenhum',
            'de forma alguma', 'em hip√≥tese alguma'
        ]
        
    def _initialize_patterns(self):
        """Inicializa padr√µes de frases e express√µes"""
        
        # FRASES POSITIVAS COMPLETAS - Peso 3.5
        self.positive_phrases = [
            # Amor e relacionamentos
            'amor da minha vida', 'pessoa mais especial', 'melhor coisa que me aconteceu',
            'n√£o consigo viver sem', 'faz meu cora√ß√£o bater mais forte',
            'amo profundamente', 'gratid√£o eterna', 'reconhecimento infinito',
            
            # Realiza√ß√µes e conquistas
            'sonho realizado', 'objetivo alcan√ßado', 'meta conquistada',
            'superou todas expectativas', 'muito al√©m do esperado',
            'tudo que eu queria', 'exatamente o que precisava',
            
            # Experi√™ncias positivas
            'experi√™ncia incr√≠vel', 'momento m√°gico', 'sensa√ß√£o maravilhosa',
            'vale muito a pena', 'recomendo fortemente', 'aprova√ß√£o total',
            'satisfa√ß√£o completa', 'felicidade plena'
        ]
        
        # FRASES NEGATIVAS COMPLETAS - Peso -3.5
        self.negative_phrases = [
            # Decep√ß√£o e frustra√ß√£o
            'maior decep√ß√£o', 'frustra√ß√£o total', 'expectativas destru√≠das',
            'sonho desfeito', 'ilus√£o perdida', 'esperan√ßa morta',
            
            # Experi√™ncias ruins
            'pior experi√™ncia', 'momento terr√≠vel', 'situa√ß√£o horr√≠vel',
            'n√£o recomendo a ningu√©m', 'evitem a todo custo',
            'perda de tempo', 'dinheiro jogado fora',
            
            # Emo√ß√µes negativas intensas
            'cora√ß√£o partido', 'alma destro√ßada', 'esp√≠rito quebrado',
            'profunda tristeza', 'dor insuport√°vel', 'sofrimento imenso'
        ]
        
    def _initialize_emoji_mapping(self):
        """Mapeia emojis para sentimentos"""
        self.emoji_sentiment = {
            # Muito positivos
            'üòç': 4, 'ü•∞': 4, 'üòò': 4, 'üíñ': 4, 'üíï': 4, '‚ù§Ô∏è': 4,
            'ü§©': 3.5, 'üòä': 3.5, 'üòÅ': 3.5, 'ü§ó': 3.5,
            
            # Positivos
            'üòÄ': 3, 'üòÉ': 3, 'üòÑ': 3, 'üòÜ': 3, 'üôÇ': 2.5, 'üòâ': 2.5,
            'üëç': 2, 'üëè': 2, 'üéâ': 3, 'üåü': 2.5,
            
            # Neutros
            'üòê': 0, 'üòë': 0, 'ü§î': 0, 'üò∂': 0,
            
            # Negativos
            'üòû': -2.5, 'üòî': -2.5, 'üòü': -2, 'üòï': -2, 'üôÅ': -2,
            'üòí': -1.5, 'üò§': -2, 'üëé': -2,
            
            # Muito negativos
            'üò≠': -3.5, 'üò¢': -3, 'üò®': -3, 'üò∞': -3.5, 'üò±': -4,
            'ü§¨': -4, 'üò°': -4, 'üíî': -4
        }
    
    def _preprocess_text(self, text: str) -> str:
        """Preprocessa o texto para melhor an√°lise"""
        
        # Converter para min√∫sculas
        text = text.lower().strip()
        
        # Expandir contra√ß√µes comuns
        contractions = {
            "n√£o √©": "n√£o √©",
            "isn't": "is not",
            "wasn't": "was not", 
            "won't": "will not",
            "can't": "cannot",
            "shouldn't": "should not",
            "wouldn't": "would not",
            "couldn't": "could not"
        }
        
        for contraction, expansion in contractions.items():
            text = text.replace(contraction, expansion)
            
        # Normalizar repeti√ß√µes excessivas (ex: "muuuito" -> "muito")
        text = re.sub(r'(.)\1{2,}', r'\1\1', text)
        
        # Normalizar pontua√ß√£o m√∫ltipla
        text = re.sub(r'[!]{2,}', '!', text)
        text = re.sub(r'[?]{2,}', '?', text)
        
        return text
    
    def _extract_emojis(self, text: str) -> List[str]:
        """Extrai emojis do texto"""
        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map symbols
            "\U0001F1E0-\U0001F1FF"  # flags
            "\U00002702-\U000027B0"
            "\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE
        )
        return emoji_pattern.findall(text)
    
    def _analyze_ngrams(self, words: List[str], n: int = 2) -> Dict[str, float]:
        """Analisa n-gramas para capturar contexto"""
        ngram_scores = {}
        
        for i in range(len(words) - n + 1):
            ngram = ' '.join(words[i:i+n])
            
            # Verificar se √© uma frase conhecida
            if ngram in self.positive_phrases:
                ngram_scores[ngram] = 3.5
            elif ngram in self.negative_phrases:
                ngram_scores[ngram] = -3.5
            else:
                # Analisar componentes do n-grama
                score = 0
                for word in words[i:i+n]:
                    if word in self.very_positive:
                        score += 4
                    elif word in self.positive_words:
                        score += 2.5
                    elif word in self.light_positive:
                        score += 1
                    elif word in self.very_negative:
                        score -= 4
                    elif word in self.negative_words:
                        score -= 2.5
                    elif word in self.light_negative:
                        score -= 1
                
                if score != 0:
                    ngram_scores[ngram] = score / n
        
        return ngram_scores
    
    def _analyze_context_window(self, words: List[str], sentiment_word_idx: int, window_size: int = 3) -> Dict[str, Any]:
        """Analisa janela de contexto ao redor de palavra de sentimento"""
        context = {
            'negated': False,
            'intensified': False,
            'diminished': False,
            'modifier_strength': 1.0
        }
        
        # Verificar palavras anteriores
        start_idx = max(0, sentiment_word_idx - window_size)
        preceding_words = words[start_idx:sentiment_word_idx]
        
        for word in preceding_words:
            if word in self.negators:
                context['negated'] = True
            elif word in self.intensifiers:
                context['intensified'] = True
                context['modifier_strength'] *= 1.6
            elif word in self.diminishers:
                context['diminished'] = True
                context['modifier_strength'] *= 0.6
        
        return context
    
    def _detect_sarcasm_indicators(self, text: str, words: List[str]) -> Dict[str, Any]:
        """Detecta poss√≠veis indicadores de sarcasmo/ironia"""
        sarcasm_score = 0
        indicators = []
        
        # Padr√µes sarc√°sticos comuns
        sarcastic_patterns = [
            'claro que sim', 'com certeza', 'que maravilha', 'perfeito mesmo',
            'exatamente o que eu queria', 'que surpresa', 'como n√£o',
            'obviamente', 'certamente', 'sem d√∫vida'
        ]
        
        for pattern in sarcastic_patterns:
            if pattern in text:
                sarcasm_score += 0.3
                indicators.append(pattern)
        
        # Pontua√ß√£o excessiva pode indicar sarcasmo
        if '!!!' in text or '???' in text:
            sarcasm_score += 0.2
            indicators.append('pontua√ß√£o excessiva')
        
        # Aspas podem indicar ironia
        if '"' in text or "'" in text:
            sarcasm_score += 0.1
            indicators.append('aspas')
        
        # Contradi√ß√£o: palavras positivas seguidas de contexto negativo
        positive_count = sum(1 for word in words if word in self.positive_words or word in self.very_positive)
        negative_count = sum(1 for word in words if word in self.negative_words or word in self.very_negative)
        
        if positive_count > 0 and negative_count > positive_count:
            sarcasm_score += 0.4
            indicators.append('contradi√ß√£o positivo-negativo')
        
        return {
            'sarcasm_probability': min(sarcasm_score, 1.0),
            'indicators': indicators
        }
    
    def _analyze_emotions(self, words: List[str]) -> Dict[str, float]:
        """Analisa emo√ß√µes espec√≠ficas al√©m do sentimento geral"""
        emotions = {
            'alegria': 0, 'tristeza': 0, 'raiva': 0, 'medo': 0, 
            'surpresa': 0, 'nojo': 0, 'desprezo': 0
        }
        
        emotion_words = {
            'alegria': ['feliz', 'alegre', 'contente', 'radiante', 'euf√≥rico', 'jubiloso', 
                       'exultante', 'satisfeito', 'realizado', 'orgulhoso'],
            'tristeza': ['triste', 'melanc√≥lico', 'deprimido', 'abatido', 'desanimado',
                        'desiludido', 'desolado', 'amargurado', 'enlutado', 'pesaroso'],
            'raiva': ['irritado', 'furioso', 'bravo', 'indignado', 'revoltado',
                     'col√©rico', 'irado', 'enfurecido', 'exaltado', 'enraivecido'],
            'medo': ['assustado', 'aterrorizado', 'apreensivo', 'temeroso', 'receoso',
                    'medroso', 'pavido', 'acovardado', 'inquieto', 'angustiado'],
            'surpresa': ['surpreso', 'espantado', 'chocado', 'impressionado', 'admirado',
                        'pasmo', 'estupefato', 'perplexo', 'at√¥nito', 'boquiaberto'],
            'nojo': ['nojento', 'repugnante', 'asqueroso', 'nauseante', 'repulsivo',
                    'abomin√°vel', 'execr√°vel', 'detest√°vel', 'desprez√≠vel', 'odioso'],
            'desprezo': ['desprez√≠vel', 'insignificante', 'indigno', 'vil', 'baixo',
                        'rasteiro', 'ign√≥bil', 'abjeto', 'miser√°vel', 'contempt√≠vel']
        }
        
        for emotion, emotion_word_list in emotion_words.items():
            for word in words:
                if word in emotion_word_list:
                    emotions[emotion] += 1
        
        # Normalizar scores
        total_emotion_words = sum(emotions.values())
        if total_emotion_words > 0:
            for emotion in emotions:
                emotions[emotion] = round(emotions[emotion] / total_emotion_words, 2)
        
        return emotions
    
    def _calculate_advanced_confidence(self, features: Dict[str, Any]) -> float:
        """Calcula confidence score baseado em m√∫ltiplos fatores"""
        base_confidence = 0.5
        
        # Fator 1: N√∫mero de evid√™ncias (palavras de sentimento)
        if features['sentiment_word_count'] >= 4:
            base_confidence += 0.25
        elif features['sentiment_word_count'] >= 2:
            base_confidence += 0.15
        elif features['sentiment_word_count'] == 1:
            base_confidence += 0.05
        
        # Fator 2: Presen√ßa de frases completas (alta confian√ßa)
        if features.get('phrase_matches'):
            base_confidence += 0.20
        
        # Fator 3: Consist√™ncia do sentimento
        if features.get('sentiment_consistency', 0) > 0.8:
            base_confidence += 0.15
        elif features.get('sentiment_consistency', 0) < 0.5:
            base_confidence -= 0.10
        
        # Fator 4: Presen√ßa de emojis
        if features.get('emoji_count', 0) > 0:
            base_confidence += 0.10
        
        # Fator 5: Penalidade por poss√≠vel sarcasmo
        sarcasm_prob = features.get('sarcasm_probability', 0)
        if sarcasm_prob > 0.6:
            base_confidence -= 0.30
        elif sarcasm_prob > 0.3:
            base_confidence -= 0.15
        
        # Fator 6: Tamanho do texto
        text_length = features.get('text_length', 0)
        if text_length < 3:  # Texto muito curto
            base_confidence -= 0.20
        elif text_length > 20:  # Texto longo com mais contexto
            base_confidence += 0.10
        
        # Fator 7: Presen√ßa de intensificadores
        if features.get('has_intensifiers'):
            base_confidence += 0.10
        
        return max(0.2, min(0.98, base_confidence))
    
    def analyze(self, text: str) -> Dict[str, Any]:
        """An√°lise principal de sentimento com IA avan√ßada"""
        if not text or not text.strip():
            raise ValueError("Text input is required")
        
        # Preprocessamento
        original_text = text
        processed_text = self._preprocess_text(text)
        words = processed_text.split()
        
        # Extrair emojis
        emojis = self._extract_emojis(original_text)
        
        # Inicializar vari√°veis de an√°lise
        sentiment_score = 0
        sentiment_word_count = 0
        context_analyses = []
        phrase_matches = []
        
        # ETAPA 1: An√°lise de frases completas (maior prioridade)
        for phrase in self.positive_phrases:
            if phrase in processed_text:
                sentiment_score += 3.5
                sentiment_word_count += 2
                phrase_matches.append(f"+{phrase}")
        
        for phrase in self.negative_phrases:
            if phrase in processed_text:
                sentiment_score -= 3.5
                sentiment_word_count += 2
                phrase_matches.append(f"-{phrase}")
        
        # ETAPA 2: An√°lise de n-gramas (contexto local)
        if not phrase_matches:
            bigram_scores = self._analyze_ngrams(words, 2)
            trigram_scores = self._analyze_ngrams(words, 3)
            
            for ngram, score in {**bigram_scores, **trigram_scores}.items():
                sentiment_score += score
                sentiment_word_count += 1
                if score > 0:
                    phrase_matches.append(f"+{ngram}")
                else:
                    phrase_matches.append(f"-{ngram}")
        
        # ETAPA 3: An√°lise palavra por palavra com contexto
        if not phrase_matches and not bigram_scores and not trigram_scores:
            for i, word in enumerate(words):
                word_score = 0
                
                # Determinar score base da palavra
                if word in self.very_positive:
                    word_score = 4
                elif word in self.positive_words:
                    word_score = 2.5
                elif word in self.light_positive:
                    word_score = 1
                elif word in self.very_negative:
                    word_score = -4
                elif word in self.negative_words:
                    word_score = -2.5
                elif word in self.light_negative:
                    word_score = -1
                
                if word_score != 0:
                    sentiment_word_count += 1
                    
                    # Analisar contexto da palavra
                    context = self._analyze_context_window(words, i)
                    context_analyses.append(context)
                    
                    # Aplicar modificadores de contexto
                    word_score *= context['modifier_strength']
                    
                    # Aplicar nega√ß√£o
                    if context['negated']:
                        word_score *= -1
                    
                    sentiment_score += word_score
        
        # ETAPA 4: An√°lise de emojis
        emoji_score = 0
        for emoji in emojis:
            if emoji in self.emoji_sentiment:
                emoji_score += self.emoji_sentiment[emoji]
        
        # Normalizar score de emoji (peso menor que palavras)
        if emoji_score != 0:
            sentiment_score += emoji_score * 0.7
            sentiment_word_count += len(emojis)
        
        # ETAPA 5: Calcular score m√©dio
        if sentiment_word_count > 0:
            avg_sentiment = sentiment_score / sentiment_word_count
        else:
            avg_sentiment = 0
        
        # ETAPA 6: An√°lises complementares
        sarcasm_analysis = self._detect_sarcasm_indicators(processed_text, words)
        emotion_analysis = self._analyze_emotions(words)
        
        # ETAPA 7: Determina√ß√£o do r√≥tulo final
        # Ajustar por sarcasmo
        if sarcasm_analysis['sarcasm_probability'] > 0.6:
            avg_sentiment *= -1  # Inverter por sarcasmo
        
        # Classificar sentimento
        if avg_sentiment >= 2.0:
            label = "POSITIVE"
        elif avg_sentiment >= 0.5:
            label = "POSITIVE"
        elif avg_sentiment <= -2.0:
            label = "NEGATIVE"
        elif avg_sentiment <= -0.5:
            label = "NEGATIVE"
        else:
            label = "NEUTRAL"
        
        # ETAPA 8: Calcular confidence avan√ßado
        features = {
            'sentiment_word_count': sentiment_word_count,
            'phrase_matches': phrase_matches,
            'sentiment_consistency': abs(avg_sentiment) / 4 if avg_sentiment != 0 else 0,
            'emoji_count': len(emojis),
            'sarcasm_probability': sarcasm_analysis['sarcasm_probability'],
            'text_length': len(words),
            'has_intensifiers': any(word in self.intensifiers for word in words)
        }
        
        confidence = self._calculate_advanced_confidence(features)
        
        # Penalidade adicional por sarcasmo
        if sarcasm_analysis['sarcasm_probability'] > 0.3:
            confidence *= (1 - sarcasm_analysis['sarcasm_probability'] * 0.5)
        
        return {
            "label": label,
            "score": float(round(confidence, 3)),
            "sentiment_intensity": float(round(abs(avg_sentiment), 2)),
            "emotions": emotion_analysis,
            "sarcasm": {
                "probability": float(round(sarcasm_analysis['sarcasm_probability'], 2)),
                "indicators": sarcasm_analysis['indicators']
            },
            "debug": {
                "words_analyzed": sentiment_word_count,
                "raw_score": float(round(sentiment_score, 2)),
                "avg_score": float(round(avg_sentiment, 2)),
                "phrase_matches": phrase_matches[:5],  # M√°ximo 5 para n√£o sobrecarregar
                "emoji_count": len(emojis),
                "text_length": len(words),
                "preprocessing": {
                    "original_length": len(original_text),
                    "processed_length": len(processed_text),
                    "emoji_found": emojis
                }
            }
        }
