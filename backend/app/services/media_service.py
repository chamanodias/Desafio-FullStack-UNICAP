"""
Servi√ßo de Processamento de M√≠dia

Respons√°vel por processar imagens (OCR) e √°udios (Speech-to-Text)
para extra√ß√£o de texto que pode ser analisado para sentimentos
"""
import os
import io
import base64
import tempfile
import logging
from typing import Dict, Any, Optional, Union
from pathlib import Path
import asyncio

from ..config import config

# Importa√ß√µes condicionais - instalar apenas se necess√°rio
try:
    from PIL import Image, ImageEnhance
    import cv2
    import numpy as np
    HAS_IMAGE_SUPPORT = True
except ImportError:
    HAS_IMAGE_SUPPORT = False

try:
    import speech_recognition as sr
    from pydub import AudioSegment
    import librosa
    HAS_AUDIO_SUPPORT = True
except ImportError:
    HAS_AUDIO_SUPPORT = False

try:
    import pytesseract
    HAS_TESSERACT_OCR = True
except ImportError:
    HAS_TESSERACT_OCR = False

logger = logging.getLogger(__name__)


class MediaService:
    """Servi√ßo principal para processamento de m√≠dia"""
    
    def __init__(self):
        self.image_processor = ImageProcessor() if HAS_IMAGE_SUPPORT else None
        self.audio_processor = AudioProcessor() if HAS_AUDIO_SUPPORT else None
        
        logger.info(f"üéûÔ∏è MediaService inicializado - Imagem: {bool(self.image_processor)}, √Åudio: {bool(self.audio_processor)}")
    
    async def process_image(
        self, 
        image_data: str, 
        filename: str, 
        extract_text: bool = True
    ) -> Dict[str, Any]:
        """
        Processa uma imagem e extrai texto via OCR
        
        Args:
            image_data: Imagem em base64
            filename: Nome do arquivo
            extract_text: Se deve extrair texto
            
        Returns:
            Dict com texto extra√≠do e metadados
        """
        if not self.image_processor:
            raise ValueError("Processamento de imagens n√£o dispon√≠vel. Instale as depend√™ncias necess√°rias.")
        
        # Executar processamento em thread separada (opera√ß√£o pesada)
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None, 
            self.image_processor.process, 
            image_data, 
            filename, 
            extract_text
        )
        
        return {
            **result,
            "media_type": "image",
            "filename": filename
        }
    
    async def process_audio(
        self, 
        audio_data: str, 
        filename: str, 
        language: str = "pt-BR"
    ) -> Dict[str, Any]:
        """
        Processa um √°udio e converte fala em texto
        
        Args:
            audio_data: √Åudio em base64
            filename: Nome do arquivo
            language: Idioma do √°udio
            
        Returns:
            Dict com texto transcrito e metadados
        """
        if not self.audio_processor:
            raise ValueError("Processamento de √°udios n√£o dispon√≠vel. Instale as depend√™ncias necess√°rias.")
        
        # Executar processamento em thread separada (opera√ß√£o pesada)
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None, 
            self.audio_processor.process, 
            audio_data, 
            filename, 
            language
        )
        
        return {
            **result,
            "media_type": "audio",
            "filename": filename
        }
    
    def get_capabilities(self) -> Dict[str, Any]:
        """Retorna as capacidades dispon√≠veis"""
        return {
            "image_processing": bool(self.image_processor),
            "audio_processing": bool(self.audio_processor),
            "ocr_available": HAS_TESSERACT_OCR or True,  # Sempre True por ter m√©todo alternativo
            "speech_recognition": HAS_AUDIO_SUPPORT,
            "supported_image_formats": config.ALLOWED_IMAGE_EXTENSIONS,
            "supported_audio_formats": config.ALLOWED_AUDIO_EXTENSIONS
        }


class ImageProcessor:
    """Processador espec√≠fico para imagens"""
    
    def __init__(self):
        self.supported_formats = config.ALLOWED_IMAGE_EXTENSIONS
        
    def process(self, image_data: str, filename: str, extract_text: bool = True) -> Dict[str, Any]:
        """Processa imagem e extrai texto"""
        try:
            # Limpar dados base64
            if image_data.startswith('data:image'):
                image_data = image_data.split(',')[1]
            
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # Converter para RGB se necess√°rio
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Metadados b√°sicos da imagem
            result = {
                "file_size": len(image_bytes),
                "dimensions": {"width": image.size[0], "height": image.size[1]},
                "processing_method": "pil_image"
            }
            
            # Extrair texto se solicitado
            if extract_text:
                extracted_text = self._extract_text_from_image(image)
                result.update({
                    "extracted_text": extracted_text,
                    "processing_method": "ocr_multi_method"
                })
            else:
                result["extracted_text"] = None
            
            return result
            
        except Exception as e:
            logger.error(f"Erro ao processar imagem {filename}: {e}")
            raise ValueError(f"Erro ao processar imagem: {str(e)}")
    
    def _extract_text_from_image(self, image: Image.Image) -> str:
        """Extrai texto usando m√∫ltiplos m√©todos OCR"""
        # Melhorar imagem para OCR
        enhanced_image = self._enhance_for_ocr(image)
        
        # M√©todo 1: Tesseract (se dispon√≠vel)
        if HAS_TESSERACT_OCR:
            try:
                text = pytesseract.image_to_string(enhanced_image, lang='por')
                if text.strip():
                    return self._clean_text(text)
            except Exception as e:
                logger.warning(f"Tesseract OCR falhou: {e}")
        
        # M√©todo 2: An√°lise de contraste e padr√µes
        fallback_text = self._analyze_image_patterns(enhanced_image)
        return self._clean_text(fallback_text)
    
    def _enhance_for_ocr(self, image: Image.Image) -> Image.Image:
        """Melhora imagem para OCR"""
        # Aumentar contraste
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(1.2)
        
        # Aumentar nitidez
        enhancer = ImageEnhance.Sharpness(image)
        image = enhancer.enhance(1.1)
        
        # Redimensionar se muito pequena
        if image.size[0] < 300 or image.size[1] < 300:
            scale = 2
            new_size = (int(image.size[0] * scale), int(image.size[1] * scale))
            image = image.resize(new_size, Image.Resampling.LANCZOS)
        
        return image
    
    def _analyze_image_patterns(self, image: Image.Image) -> str:
        """M√©todo alternativo de an√°lise quando OCR n√£o funciona"""
        try:
            # Converter para array numpy
            img_array = np.array(image)
            
            # Detectar se h√° muito texto (√°reas com contraste)
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            edges = cv2.Canny(gray, 50, 150)
            
            # Contar pixels de borda (indicativo de texto)
            edge_pixels = np.count_nonzero(edges)
            total_pixels = gray.size
            edge_ratio = edge_pixels / total_pixels
            
            # Analisar histograma (distribui√ß√£o de cores)
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            contrast = np.std(hist)
            
            # Gerar texto descritivo baseado na an√°lise
            if edge_ratio > 0.1:  # Muitas bordas = prov√°vel presen√ßa de texto
                if contrast > 1000:  # Alto contraste
                    return "Imagem com texto de alto contraste detectado"
                else:
                    return "Imagem com poss√≠vel texto de baixo contraste"
            else:
                if contrast > 500:
                    return "Imagem com elementos gr√°ficos variados"
                else:
                    return "Imagem com conte√∫do uniforme ou poucos detalhes"
                    
        except Exception as e:
            logger.warning(f"An√°lise de padr√µes falhou: {e}")
            return "Imagem processada sem extra√ß√£o de texto"
    
    def _clean_text(self, text: str) -> str:
        """Limpa texto extra√≠do"""
        if not text:
            return ""
        
        # Remover caracteres especiais e normalizar
        text = text.strip()
        text = ' '.join(text.split())  # Normalizar espa√ßos
        
        # Remover linhas muito curtas (provavelmente ru√≠do)
        lines = [line.strip() for line in text.split('\n') if len(line.strip()) > 2]
        
        return ' '.join(lines)


class AudioProcessor:
    """Processador espec√≠fico para √°udios"""
    
    def __init__(self):
        self.supported_formats = config.ALLOWED_AUDIO_EXTENSIONS
        self.recognizer = sr.Recognizer()
    
    def process(self, audio_data: str, filename: str, language: str = "pt-BR") -> Dict[str, Any]:
        """Processa √°udio e extrai texto via Speech-to-Text"""
        try:
            # Limpar dados base64
            if audio_data.startswith('data:audio'):
                audio_data = audio_data.split(',')[1]
            
            audio_bytes = base64.b64decode(audio_data)
            
            # Processar √°udio em arquivo tempor√°rio
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(audio_bytes)
                temp_audio_path = temp_file.name
            
            try:
                # Carregar e normalizar √°udio
                audio_segment = AudioSegment.from_file(temp_audio_path)
                audio_segment = audio_segment.set_frame_rate(16000).set_channels(1)
                
                # Salvar vers√£o processada
                processed_path = temp_audio_path.replace('.wav', '_processed.wav')
                audio_segment.export(processed_path, format="wav")
                
                # Extrair texto
                extracted_text = self._speech_to_text(processed_path, language)
                
                return {
                    "extracted_text": extracted_text,
                    "file_size": len(audio_bytes),
                    "duration": len(audio_segment) / 1000,  # segundos
                    "processing_method": "speech_recognition"
                }
                
            finally:
                # Limpar arquivos tempor√°rios
                for path in [temp_audio_path, processed_path]:
                    if os.path.exists(path):
                        os.unlink(path)
                        
        except Exception as e:
            logger.error(f"Erro ao processar √°udio {filename}: {e}")
            raise ValueError(f"Erro ao processar √°udio: {str(e)}")
    
    def _speech_to_text(self, audio_path: str, language: str) -> str:
        """Converte fala em texto"""
        try:
            with sr.AudioFile(audio_path) as source:
                # Ajustar para ru√≠do ambiente
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                audio_data = self.recognizer.record(source)
            
            # Tentar m√∫ltiplos engines
            engines = [
                ('google', lambda: self.recognizer.recognize_google(audio_data, language=language)),
                ('sphinx', lambda: self.recognizer.recognize_sphinx(audio_data))
            ]
            
            for engine_name, engine_func in engines:
                try:
                    text = engine_func()
                    if text.strip():
                        logger.info(f"‚úÖ Texto extra√≠do com {engine_name}: {len(text)} chars")
                        return text
                except Exception as e:
                    logger.warning(f"Engine {engine_name} falhou: {e}")
                    continue
            
            return ""  # Nenhum engine funcionou
            
        except Exception as e:
            logger.error(f"Erro no speech-to-text: {e}")
            return ""
