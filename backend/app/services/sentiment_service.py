"""
Servi√ßo de An√°lise de Sentimentos

Cont√©m toda a l√≥gica de an√°lise de sentimentos, incluindo an√°lise local
e integra√ß√£o com APIs externas (Hugging Face)
"""
import asyncio
import logging
from typing import Dict, Any, Optional, List
import requests
import json

from ..config import config

logger = logging.getLogger(__name__)


class SentimentService:
    """Servi√ßo principal para an√°lise de sentimentos"""
    
    def __init__(self):
        self.local_analyzer = LocalSentimentAnalyzer()
        self._external_api_available = bool(config.HUGGINGFACE_API_KEY)
        
        if self._external_api_available:
            logger.info("ü§ó API externa Hugging Face configurada")
        else:
            logger.info("üè† Usando apenas an√°lise local")
    
    async def analyze_sentiment(
        self, 
        text: str, 
        use_external: bool = False, 
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Analisa o sentimento de um texto
        
        Args:
            text: Texto para an√°lise
            use_external: Se deve tentar usar API externa
            options: Op√ß√µes adicionais (source, language, etc.)
            
        Returns:
            Dict com label, score e informa√ß√µes de debug
        """
        if not text or not text.strip():
            raise ValueError("Texto n√£o pode estar vazio")
        
        text = text.strip()
        options = options or {}
        
        # Decidir qual m√©todo usar
        if use_external and self._external_api_available:
            try:
                result = await self._analyze_external(text, options)
                logger.info(f"‚úÖ An√°lise externa conclu√≠da: {result['label']} ({result['score']:.3f})")
                return result
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Falha na API externa, usando an√°lise local: {e}")
                # Fallback para an√°lise local
        
        # Usar an√°lise local
        result = self.local_analyzer.analyze(text, options)
        logger.info(f"‚úÖ An√°lise local conclu√≠da: {result['label']} ({result['score']:.3f})")
        return result
    
    async def _analyze_external(self, text: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """Analisa usando API externa (Hugging Face)"""
        if not config.HUGGINGFACE_API_KEY:
            raise ValueError("HUGGINGFACE_API_KEY n√£o configurada")
        
        # Modelo otimizado para portugu√™s
        model = "pysentimiento/robertuito-sentiment-analysis"
        url = f"{config.HUGGINGFACE_API_URL}/{model}"
        
        headers = {
            "Authorization": f"Bearer {config.HUGGINGFACE_API_KEY}",
            "Content-Type": "application/json"
        }
        
        payload = {"inputs": text}
        
        # Fazer requisi√ß√£o (bloqueante, mas em thread separada)
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, lambda: requests.post(url, headers=headers, json=payload, timeout=config.REQUEST_TIMEOUT)
        )
        
        if response.status_code != 200:
            raise Exception(f"API externa falhou: {response.status_code} - {response.text}")
        
        result = response.json()
        
        # Processar resultado da API
        if isinstance(result, list) and len(result) > 0:
            predictions = result[0]
            
            # Encontrar a melhor predi√ß√£o
            best_pred = max(predictions, key=lambda x: x['score'])
            
            # Mapear labels para nosso padr√£o
            label_mapping = {
                'POSITIVE': 'POSITIVE',
                'POS': 'POSITIVE',
                'NEGATIVE': 'NEGATIVE', 
                'NEG': 'NEGATIVE',
                'NEUTRAL': 'NEUTRAL',
                'NEU': 'NEUTRAL'
            }
            
            mapped_label = label_mapping.get(best_pred['label'].upper(), 'NEUTRAL')
            
            return {
                'label': mapped_label,
                'score': float(best_pred['score']),
                'debug': {
                    'method': 'external_api',
                    'model': model,
                    'raw_predictions': predictions,
                    'source': options.get('source', 'text')
                }
            }
        
        raise ValueError("Formato de resposta inv√°lido da API externa")


class LocalSentimentAnalyzer:
    """Analisador de sentimento local baseado em regras e palavras-chave"""
    
    def __init__(self):
        self._load_sentiment_data()
    
    def _load_sentiment_data(self):
        """Carrega dados de palavras e frases para an√°lise"""
        
        # Palavras MUITO positivas - Alegria intensa (peso 4)
        self.very_positive = [
            'amo', 'adoro', 'love', 'excelente', 'excellent', 'fant√°stico', 'fantastic',
            'maravilhoso', 'wonderful', 'incr√≠vel', 'incredible', 'perfeito', 'perfect',
            'sensacional', 'espetacular', 'extraordin√°rio', 'magn√≠fico', 'divino',
            'alegria', 'felicidade', 'euforia', '√™xtase', 'radiante', 'encantado',
            'deslumbrado', 'fascinado', 'gratid√£o', 'ternura', 'sorrir', 'sorrindo',
            'nunca imaginei', 'tomou conta', 'mais do que tudo'
        ]
        
        # Palavras positivas - Sentimentos bons (peso 2.5)
        self.positive_words = [
            '√≥timo', 'great', 'bom', 'good', 'feliz', 'happy', 'adorei', 'loved',
            'recomendo', 'recommend', 'melhor', 'best', 'amazing', 'legal', 'bacana',
            'gostei', 'like', 'aprovado', 'sucesso', 'show', 'top', 'massa', 'demais',
            'esperan√ßa', 'otimismo', 'confian√ßa', 'satisfeito', 'contente', 'orgulhoso',
            'animado', 'entusiasmado', 'inspirado', 'motivado', 'tudo vai dar certo',
            'amor da minha vida', 'especial', 'presente', 'surpresa', 'expectativa'
        ]
        
        # Palavras levemente positivas (peso 1)
        self.light_positive = [
            'ok', 'okay', 'aceit√°vel', 'razo√°vel', 'decent', 'not bad', 'pode ser',
            'interessante', '√∫til', 'v√°lido', 'funciona', 'serve', 'normal', 'regular',
            'ansioso', 'curioso', 'esperando', 'aguardando'
        ]
        
        # Palavras MUITO negativas - Sentimentos intensos ruins (peso -4)
        self.very_negative = [
            'odeio', 'detesto', 'hate', 'terr√≠vel', 'terrible', 'p√©ssimo', 'awful',
            'horr√≠vel', 'horrible', 'odioso', 'hateful', 'nojento', 'lixo', 'merda',
            'raiva', '√≥dio', 'f√∫ria', 'irritado', 'extremamente irritado', 'pavor',
            'p√¢nico', 'terror', 'desespero', 'devastado', 'destru√≠do', 'arrasado',
            'n√£o conseguiu esconder', 'profunda tristeza', 'cora√ß√£o pesado'
        ]
        
        # Palavras negativas - Tristeza e problemas (peso -2.5)
        self.negative_words = [
            'ruim', 'bad', 'triste', 'sad', 'pior', 'worst', 'n√£o gosto', "don't like",
            'n√£o recomendo', "don't recommend", 'chato', 'boring', 'desapontado', 'disappointed',
            'tristeza', 'melancolia', 'saudade', 'l√°grimas', 'choro', 'chorando',
            'medo', 'medo do escuro', 'desconhecido', 'sozinhas', 'assustado',
            'preocupado', 'angustiado', 'estressado', 'tenso', 'nervoso',
            'decepcionado', 'frustrado', 'magoado', 'machucado', 'ferido'
        ]
        
        # Palavras levemente negativas (peso -1)
        self.light_negative = [
            'estranho', 'weird', 'confuso', 'confusing', 'dif√≠cil', 'hard', 'complicado',
            'problema', 'issue', 'erro', 'error', 'falha', 'bug', 'cansado', 'fatiga',
            'ansiedade', 'preocupa√ß√£o', 'd√∫vida', 'incerteza', 'inseguro', 'receoso'
        ]
        
        # Intensificadores - aumentam o peso das palavras
        self.intensifiers = [
            'muito', 'super', 'extremely', 'really', 'totally', 'absolutely',
            'completamente', 'demais', 'bastante', 'quite', 'bem', 'mega',
            'extremamente', 'profundamente', 'incrivelmente', 'imensamente',
            'profunda', 'intensa', 'grande', 'enorme', 'tanto', 'tanta'
        ]
        
        # Negadores - invertem o sentimento
        self.negators = [
            'n√£o', 'not', 'nunca', 'never', 'jamais', 'nenhum', 'nenhuma',
            'sem', 'without', 'imposs√≠vel', 'impossible', 'nem', 'nada de',
            'deixou de', 'parou de', 'falhou em'
        ]
        
        # Frases completas positivas (peso 3)
        self.positive_phrases = [
            'estou me sentindo muito feliz', 'alegria tomou conta', 'nunca imaginei que pudesse sorrir',
            'tenho esperan√ßa de que tudo', 'amor da minha vida', 'amo minha fam√≠lia',
            'sinto ternura em tudo', 'profunda gratid√£o', 'tudo vai dar certo',
            'mal posso esperar', 'n√£o esperava receber', 'presente t√£o especial'
        ]
        
        # Frases completas negativas (peso -3)
        self.negative_phrases = [
            'senti uma tristeza profunda', 'cora√ß√£o est√° pesado', 'n√£o consigo segurar as l√°grimas',
            'com muita raiva', 'extremamente irritado', 'n√£o conseguiu esconder a raiva',
            'tenho medo do escuro', 'senti um pavor', 'est√£o com medo', 'ansiedade constante',
            'decepcionado com', 'tomado pela melancolia'
        ]
    
    def analyze(self, text: str, options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Analisa o sentimento usando m√©todo local
        
        Args:
            text: Texto para an√°lise
            options: Op√ß√µes adicionais
            
        Returns:
            Dict com label, score e debug info
        """
        options = options or {}
        
        if not text:
            raise ValueError("Texto √© obrigat√≥rio")
        
        text_lower = text.lower().strip()
        words = text_lower.split()
        
        # Para textos muito curtos, ser mais conservador
        is_short_text = len(words) <= 2
        
        score = 0
        word_count = 0
        phrase_matches = []
        
        # ETAPA 1: Verificar frases completas primeiro (prioridade m√°xima)
        for phrase in self.positive_phrases:
            if phrase in text_lower:
                score += 3.5
                word_count += 2
                phrase_matches.append(f"+{phrase}")
        
        for phrase in self.negative_phrases:
            if phrase in text_lower:
                score -= 3.5
                word_count += 2
                phrase_matches.append(f"-{phrase}")
        
        # ETAPA 2: An√°lise palavra por palavra (se n√£o achou frases completas)
        if not phrase_matches:
            for i, word in enumerate(words):
                word_score = self._get_word_score(word)
                
                # Se encontrou uma palavra de sentimento
                if word_score != 0:
                    word_count += 1
                    
                    # Verificar intensificadores nas 2 palavras anteriores
                    for j in range(max(0, i-2), i):
                        if words[j] in self.intensifiers:
                            word_score *= 1.6  # Aumenta o peso em 60%
                            break
                    
                    # Verificar negadores nas 3 palavras anteriores
                    for j in range(max(0, i-3), i):
                        if words[j] in self.negators:
                            word_score *= -1  # Inverte o sentimento
                            break
                    
                    score += word_score
        
        # ETAPA 3: Fallback - se n√£o encontrou nada
        if word_count == 0:
            # Detectar padr√µes de pontua√ß√£o e emojis
            if any(pattern in text_lower for pattern in ['!!!', '!', ':)', 'üòä', '‚ù§', 'nossa', 'uau']):
                score = 1
                word_count = 1
            elif any(pattern in text_lower for pattern in [':(', 'üòû', 'üíî', '???']):
                score = -1
                word_count = 1
            else:
                score = 0
                word_count = 1
        
        # Normalizar pontua√ß√£o
        if word_count > 0:
            normalized_score = score / word_count
            
            # Aplicar ajustes para textos curtos
            if is_short_text:
                normalized_score *= 0.7
            
            # Converter para escala 0-1
            confidence = min(abs(normalized_score) / 4.0, 1.0)  # Dividir por peso m√°ximo
            
            # Determinar label
            if normalized_score > 0.3:
                label = 'POSITIVE'
            elif normalized_score < -0.3:
                label = 'NEGATIVE'
            else:
                label = 'NEUTRAL'
        else:
            normalized_score = 0
            confidence = 0.5
            label = 'NEUTRAL'
        
        return {
            'label': label,
            'score': round(confidence, 3),
            'debug': {
                'method': 'local_analysis',
                'raw_score': round(normalized_score, 3),
                'words_analyzed': word_count,
                'phrase_matches': phrase_matches,
                'is_short_text': is_short_text,
                'source': options.get('source', 'text')
            }
        }
    
    def _get_word_score(self, word: str) -> float:
        """Retorna a pontua√ß√£o de uma palavra espec√≠fica"""
        if word in self.very_positive:
            return 4.0
        elif word in self.positive_words:
            return 2.5
        elif word in self.light_positive:
            return 1.0
        elif word in self.very_negative:
            return -4.0
        elif word in self.negative_words:
            return -2.5
        elif word in self.light_negative:
            return -1.0
        else:
            return 0.0
